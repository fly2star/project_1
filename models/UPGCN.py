# models/UPGCN.py
import torch
import torch.nn as nn
import torch.nn.functional as F

class UncertaintyPrunedGCN(nn.Module):
    def __init__(self, in_features, hidden_features, dropout=0.5):
        """
        ä¸ç¡®å®šæ€§å‰ªæå›¾å·ç§¯ç½‘ç»œ (Uncertainty-Pruned GCN)
        :param in_features: è¾“å…¥ç‰¹å¾ç»´åº¦ (é€šå¸¸ç­‰äº bit æ•°)
        :param hidden_features: è¾“å‡ºç‰¹å¾ç»´åº¦
        """
        super(UncertaintyPrunedGCN, self).__init__()
        self.fc = nn.Linear(in_features, hidden_features)
        self.dropout = nn.Dropout(dropout)
        self.relu = nn.ReLU()
        
        # ğŸŒŸ æ ¸å¿ƒå®‰å…¨æœºåˆ¶ï¼šå¯å­¦ä¹ çš„ alpha å‚æ•°
        # åˆå§‹åŒ–ä¸º 0.0ï¼Œç¡®ä¿è®­ç»ƒåˆæœŸ GCN è¾“å‡ºä¸º 0ï¼Œå®Œå…¨ä¸å½±å“åŸæ¨¡å‹æ€§èƒ½
        self.alpha = nn.Parameter(torch.tensor(0.0)) 

    def forward(self, x, u):
        """
        :param x: [Batch, Bit] - åŸå§‹å“ˆå¸Œç  (å»ºè®®æ˜¯ tanh ä¹‹å‰çš„ logitsï¼Œæˆ–è€…æ˜¯ tanh ä¹‹åçš„ä¹Ÿè¡Œ)
        :param u: [Batch, 1] - ä¸ç¡®å®šæ€§ (0~1ä¹‹é—´)
        """
        # 1. æ„å»ºæ„å›¾ç‰¹å¾ (å½’ä¸€åŒ–ï¼Œé˜²æ­¢æ¨¡é•¿å½±å“ç›¸ä¼¼åº¦)
        x_norm = F.normalize(x, p=2, dim=1)
        
        # 2. åŸºç¡€ç›¸ä¼¼åº¦çŸ©é˜µ (Cosine Similarity) -> [Batch, Batch]
        adj = torch.mm(x_norm, x_norm.t())
        
        # 3. ä¸ç¡®å®šæ€§å‰ªæ (Soft Pruning)
        # reliability: [Batch, 1], å€¼è¶Šå¤§è¶Šå¯é 
        reliability = 1.0 - u 
        
        # åªæœ‰ä¸¤ä¸ªèŠ‚ç‚¹éƒ½å¯é æ—¶ï¼Œè¾¹æƒé‡æ‰é«˜
        # mask[i, j] = rel[i] * rel[j]
        pruning_mask = torch.mm(reliability, reliability.t())

        # debug
        if adj.shape != pruning_mask.shape:
            print(f"!!! SHAPE MISMATCH ERROR !!!")
            print(f"x shape: {x.shape}")
            print(f"u shape: {u.shape}")
            print(f"adj shape: {adj.shape}")
            print(f"pruning_mask shape: {pruning_mask.shape}")
        
        # 4. æœ€ç»ˆé‚»æ¥çŸ©é˜µ
        # åŠ ä¸Šå•ä½çŸ©é˜µ I (Self-loop)ï¼Œä¿ç•™è‡ªèº«ä¿¡æ¯
        A_final = adj * pruning_mask + torch.eye(adj.shape[0], device=x.device)
        
        # 5. å½’ä¸€åŒ– (Row Normalization)
        # é¿å…åº¦å¤§çš„èŠ‚ç‚¹ç‰¹å¾æ•°å€¼çˆ†ç‚¸
        D_inv = A_final.sum(dim=1, keepdim=True).pow(-1)
        # å¤„ç†é™¤ä»¥0çš„æƒ…å†µ (è™½ç„¶åŠ äº†eyeä¸å¤ªå¯èƒ½ä¸º0ï¼Œä½†ä¸ºäº†ç¨³å¥)
        D_inv[torch.isinf(D_inv)] = 0.0
        A_norm = A_final * D_inv
        
        # 6. å›¾å·ç§¯è¿ç®—: A * ReLU(Dropout(Wx))
        h = self.fc(x) 
        h = self.dropout(h)
        h = self.relu(h)
        h_gcn = torch.mm(A_norm, h)
        
        return h_gcn